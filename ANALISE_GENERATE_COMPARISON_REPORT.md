# An√°lise Detalhada: `generate_comparison_report()`

## Fluxo Atual da Fun√ß√£o

```
INPUT: df_novo (sa√≠da de extract_and_clean_from_pdfs com colunas: Data, Horario, Programa_Bruto, Programa_Padronizado, chave)
       excel_anterior_path (caminho para planilha anterior)
       output_path (onde salvar o Excel comparado)

OUTPUT: Excel com pintura verde (NOVO/ALTERADO) e linhas amarelas separando dias
```

---

## Passo a Passo ‚Äî O Que Faz

### **PASSO 1: Leitura do Template Anterior**
```python
try:
    df_antigo = pd.read_excel(excel_anterior_path, header=0)
    if 'Data' not in df_antigo.columns: raise ValueError()
except:
    df_antigo = pd.read_excel(excel_anterior_path, header=2)
```
**O que faz:** Tenta ler Excel anterior com `header=0`. Se n√£o tiver coluna `Data`, tenta com `header=2`.

**Problema 1:** A l√≥gica tenta 2 varia√ß√µes de header mas n√£o garante que `Data` existe na segunda tentativa. Se falhar na segunda, levanta exce√ß√£o gen√©rica.

**Problema 2:** Assume que a estrutura anterior √© sempre compat√≠vel com a nova (mesmas colunas `Data`, `Horario`, etc).

---

### **PASSO 2: Limpeza de Colunas**
```python
df_antigo = df_antigo.loc[:, ~df_antigo.columns.str.contains('^Unnamed')]
df_antigo.columns = df_antigo.columns.str.strip()

if 'Programa' in df_antigo.columns:
    df_antigo.rename(columns={'Programa': 'Programa_Padronizado'}, inplace=True)
```
**O que faz:** Remove colunas com prefixo `Unnamed`, limpa espa√ßos dos nomes, renomeia `Programa` para `Programa_Padronizado`.

**Problema 3:** Pressup√µe que a coluna de programa se chama `Programa` (n√£o `Programa_Padronizado`, n√£o `Nome`, etc). Se tiver outro nome, fica sem a coluna esperada e cai em erro silencioso depois.

---

### **PASSO 3: Criar Mapas de √çndice de Dia (0‚Äì6)**
```python
df_novo['Data'] = df_novo['Data'].astype(str)
unique_dates_novo = df_novo['Data'].unique()
day_index_map_novo = {date_str: idx for idx, date_str in enumerate(unique_dates_novo)}

df_antigo['Data'] = df_antigo['Data'].astype(str)
unique_dates_antigo = df_antigo['Data'].unique()
day_index_map_antigo = {date_str: idx for idx, date_str in enumerate(unique_dates_antigo)}
```
**O que faz:** Para cada planilha, cria um mapa: `Data_string ‚Üí √≠ndice_sequencial (0, 1, 2, ...)`.

**Problema 4:** `df_novo` j√° vem com `Data` como string de `extract_and_clean_from_pdfs`. A convers√£o √© redundante.

**Problema 5:** Os mapas s√£o criados a partir da ordem de apari√ß√£o das datas **nas duas planilhas separadamente**. Se a planilha antiga tiver datas 01/11, 02/11, 03/11 e a nova tiver 03/11, 04/11, 05/11, os √≠ndices n√£o correspondem:
- Antigo: {01/11: 0, 02/11: 1, 03/11: 2}
- Novo: {03/11: 0, 04/11: 1, 05/11: 2}

A chave para 03/11 09:00 ser√° `2_09:00` na antigo, mas `0_09:00` na novo ‚Üí **mismatch autom√°tico!**

---

### **PASSO 4: Gerar Chaves de Compara√ß√£o**
```python
df_novo['chave'] = df_novo.apply(lambda row: _get_weekday_key(row, day_index_map_novo), axis=1)
df_antigo['chave'] = df_antigo.apply(lambda row: _get_weekday_key(row, day_index_map_antigo), axis=1)
```
**O que faz:** Aplica `_get_weekday_key()` a ambas planilhas, gerando chaves do tipo `"0_09:00"`.

**Problema 6:** Decorre diretamente do Problema 5 ‚Äî as chaves n√£o correspondem entre as duas planilhas!

---

### **PASSO 5: Construir Mapa de Consulta (Antigo)**
```python
db_sinopses = df_antigo.drop_duplicates(subset=['Programa_Padronizado'], keep='last')
mapa_antigo = pd.Series(df_antigo.Programa_Padronizado.values, index=df_antigo.chave).to_dict()
```
**O que faz:** 
- `db_sinopses`: Deduplica por nome do programa (guardar metadados / sinopses).
- `mapa_antigo`: Dicion√°rio chave ‚Üí nome do programa da planilha antigo.

**Problema 7:** O mapa usa **a √∫ltima ocorr√™ncia** de cada chave (`.to_dict()` sempre pega o √∫ltimo valor em caso de duplicate). Se a mesma hora ocorre 2x na antigo, s√≥ a √∫ltima fica no mapa.

**Problema 8:** Se uma chave n√£o existir na antigo (por ex., porque a data √© diferente entre os mapas), nunca ser√° encontrada ‚Üí marca como `NOVO` mesmo que o programa foi s√≥ movido de dia.

---

### **PASSO 6: Processamento de Registros (Compara√ß√£o Efetiva)**
```python
for _, row in df_novo.iterrows():
    item = {
        'Data': row['Data'], 'Horario': row['Horario'], 'Programa': row['Programa_Padronizado'],
        'Status': 'SEM MUDAN√áA'
    }
    
    # Recupera dados extras (Sinopse, etc)
    dados = db_sinopses[db_sinopses['Programa_Padronizado'] == item['Programa']]
    for col in colunas_extras:
        val = dados.iloc[0][col] if not dados.empty else ""
        item[col] = val if pd.notna(val) else ""

    # Verifica Mudan√ßas
    prog_antigo = mapa_antigo.get(row['chave'])
    if not prog_antigo: item['Status'] = 'NOVO'
    elif item['Programa'] != prog_antigo: item['Status'] = 'ALTERADO'
```
**O que faz:**
1. Para cada linha da nova grade, cria um registro com Data, Horario, Programa_Padronizado.
2. Procura na `db_sinopses` por metadados do programa (sinopse, diretor, etc).
3. Consulta `mapa_antigo` pela chave. Se n√£o achar, marca `NOVO`. Se achar mas programa diferente, marca `ALTERADO`.

**Problema 9:** A busca em `db_sinopses` usa `==` exato no nome do programa. Se houver varia√ß√£o m√≠nima (espa√ßo, acento que n√£o foi filtrado), n√£o encontra sinopse e deixa em branco.

**Problema 10:** A compara√ß√£o `item['Programa'] != prog_antigo` compara strings diretamente. Ambas j√° deveriam ser normalizadas (via `extract_and_clean_from_pdfs`), mas se houver diferen√ßa m√≠nima, marca como alterado.

**Problema 11:** O loop `for col in colunas_extras` faz uma busca **para cada linha**. Se a nova grade tem 500 linhas e 10 colunas extras, isso faz ~5000 buscas em `db_sinopses` ‚Äî ineficiente.

---

### **PASSO 7: Escrita e Pintura do Excel**
```python
wb = load_workbook(excel_anterior_path)
ws = wb.active

fill_green = PatternFill("solid", fgColor="C6EFCE")
fill_yellow = PatternFill("solid", fgColor="FFFF00")
# ...

for reg in registros:
    # Linha Amarela (Separador de Dia)
    if last_date and reg['Data'] != last_date:
        for c in range(2, len(cols_order) + 3):
            cell = ws.cell(curr_row, c)
            cell.fill = fill_yellow
            cell.border = border
        curr_row += 1
    
    last_date = reg['Data']
    is_changed = reg['Status'] in ['NOVO', 'ALTERADO']

    # Escreve Dados
    for i, col in enumerate(cols_order):
        cell = ws.cell(curr_row, i + 2)
        cell.value = reg.get(col, "")
        cell.border = border
        cell.alignment = align
        if is_changed: cell.fill = fill_green
    
    curr_row += 1

wb.save(output_path)
```
**O que faz:** Carrega o template anterior, limpa as linhas de dados (linha 4+), escreve os novos registros com pintura (verde se alterado, separador amarelo entre dias).

**Problema 12:** Carrega o arquivo anterior inteiro usando `load_workbook()` ‚Äî se o template tiver formatos/imagens/gr√°ficos, tudo √© carregado em mem√≥ria. Ineficiente para arquivos grandes.

**Problema 13:** Limpa **100 linhas no m√≠nimo** (`ws.delete_rows(start_row, amount=ws.max_row + 100)`). Se o arquivo anterior tem 50 linhas, deleta 150 ‚Äî pode afetarcuidado com mergings/formatos abaixo.

---

## Resumo dos Problemas Cr√≠ticos

| # | Problema | Impacto | Severidade |
|---|----------|--------|-----------|
| 5 | Mapas de √≠ndice de dia separados ‚Üí **chaves n√£o correspondem** | Falso positivo em mudar quase tudo | üî¥ CR√çTICO |
| 10 | Compara√ß√£o sem normaliza√ß√£o expl√≠cita | Pequenas varia√ß√µes marcam como alterado | üü† ALTO |
| 11 | Loop aninhado para buscar sinopses | Lento para grandes grades | üü° M√âDIO |
| 3 | N√£o detecta coluna `Programa` com nomes alternativos | Pode quebrar silenciosamente | üü† ALTO |
| 4 | Convers√£o redundante de `Data` para string | Micro-otimiza√ß√£o | üü¢ BAIXO |

---

## Solu√ß√£o Proposta

### **N√∫cleo do Problema: Mapas de √çndice Desalinhados**

A solu√ß√£o √© simples: **usar a mesma estrat√©gia de √≠ndice que foi usada em `extract_and_clean_from_pdfs`**.

Como `df_novo` j√° vem com `chave` calculada (no passo de extra√ß√£o), e j√° tem o √≠ndice correto, o ideal √©:

1. **Reutilizar a `chave` de `df_novo`** (j√° validada).
2. **Ao ler `df_antigo`, recriar a `chave` usando a MESMA ordem de datas que `df_novo`**.
   - Se `df_antigo` tiver datas que n√£o est√£o em `df_novo`, elas n√£o entram no mapa ‚Üí naturalmente marcadas como `NOVO`.
   - Se ambas compartilham datas, a chave ser√° id√™ntica.

### **Pseudoc√≥digo Simplificado**

```python
def generate_comparison_report(clean_schedule_df, excel_anterior_path, output_path):
    df_novo = clean_schedule_df.copy()  # J√° tem: Data, Horario, Programa_Bruto, Programa_Padronizado, chave
    
    # Ler antigo
    df_antigo = pd.read_excel(excel_anterior_path, header=0|2)
    # Normalizar colunas (renomear se precisar)
    
    # Usar o MESMO mapa de √≠ndices que foi criado em df_novo!
    unique_dates_novo = df_novo['Data'].unique()
    day_index_map = {date_str: idx for idx, date_str in enumerate(unique_dates_novo)}
    
    # Normalizar Data/Horario em df_antigo (para garantir consist√™ncia)
    # ... (convers√£o de formatos)
    
    # Gerar chaves em df_antigo usando o MESMO mapa
    df_antigo['chave'] = df_antigo.apply(lambda row: _get_weekday_key(row, day_index_map), axis=1)
    
    # Compara√ß√£o
    mapa_antigo = df_antigo.drop_duplicates(subset=['chave'], keep='last').set_index('chave')['Programa_Padronizado'].to_dict()
    
    # Loop simples
    for _, row in df_novo.iterrows():
        prog_novo = row['Programa_Padronizado']
        prog_antigo = mapa_antigo.get(row['chave'], None)
        
        if prog_antigo is None:
            status = 'NOVO'
        elif prog_novo != prog_antigo:
            status = 'ALTERADO'
        else:
            status = 'SEM MUDAN√áA'
        
        # Escrever registro
```

---

## Pr√≥ximos Passos

1. ‚úÖ Corrigir **Problema 5** (Mapas desalinhados) ‚Äî usar o mesmo mapa para ambas.
2. ‚úÖ Simplificar a busca de sinopses (usar `.to_dict()` ao inv√©s de busca em loop).
3. ‚ö†Ô∏è Melhorar tratamento de colunas vari√°veis (detec√ß√£o de coluna `Programa`).
4. üìù Remover convers√µes redundantes.

